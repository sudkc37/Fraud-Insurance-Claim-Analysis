# -*- coding: utf-8 -*-
"""Fraud_insurance_claim.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ydSzyn2Ax-yYHuU8KA41TZPzairO3_71

# Analyzing Insurance Claim Using SQL and Python

I've uploaded the dashboard chart to GitHub for your reference. Although interactive charts won't be directly viewable on GitHub, you can easily access and explore them. Simply download the project files and run them on Google Colab to fully interact with the charts.
"""

!pip install pandasql
!pip install plotly
!pip install streamlit

import pandasql as psql
import pandas as pd
import plotly.express as py
import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt

insurace_tabel = pd.read_csv('/content/insurance_data.csv')
employee_tabel = pd.read_csv('/content/employee_data.csv')
vendor_tabel = pd.read_csv('/content/vendor_data.csv')

query = """
SELECT * FROM insurace_tabel
LIMIT 5;
"""
psql.sqldf(query, locals())

query = """
SELECT * FROM employee_tabel
LIMIT 5;
"""
psql.sqldf(query,locals())

query = """
SELECT * FROM vendor_tabel
LIMIT 5;
"""
psql.sqldf(query,locals())

employee_tabel1 = psql.sqldf("""
SELECT  AGENT_ID, POSTAL_CODE AS AGENT_POSTAL_CODE, STATE As AGENT_STATE
FROM employee_tabel
""",locals())
employee_tabel1.head()

vendor_tabel1 = psql.sqldf("""
SELECT  VENDOR_ID, POSTAL_CODE As VENDOR_POSTAL_CODE, STATE As VENDOR_STATE
FROM vendor_tabel
""",locals())
vendor_tabel1.head()

# Join 3 tables based on Vendor_ID and Agent_ID 3 tables based on Vendor_ID and Agent_ID
query = """
WITH combineTable AS (SELECT * FROM insurace_tabel
INNER JOIN employee_tabel1
ON insurace_tabel.Agent_ID = employee_tabel1.Agent_ID
INNER JOIN vendor_tabel1
ON insurace_tabel.Vendor_ID = vendor_tabel1.Vendor_ID
)
SELECT * FROM combineTable;

"""
combineTable = psql.sqldf(query,locals())
combineTable.head()

#TOTAL Claim Filed by Each Agent
query = """
SELECT
AGENT_ID,
AGENT_STATE,
SUM(CLAIM_AMOUNT) AS TOTAL_CLAIM_AMOUNT,
ROUND(AVG(CLAIM_AMOUNT),2) AS AVERAGE_CLAIM,
(SUM(CLAIM_AMOUNT) / CAST((SELECT SUM(CLAIM_AMOUNT) FROM combineTable) AS FLOAT) * 100) AS PERCENTAGE_TOTAL_CLAIM,
(SUM(CASE WHEN CLAIM_STATUS = 'D' THEN 1 ELSE 0 END) / CAST((SELECT COUNT(*) FROM combineTable WHERE CLAIM_STATUS = 'D') AS FLOAT) * 100) AS LIKELIHOOD_FRAUD_CLAIM
FROM combineTable
GROUP BY AGENT_ID
ORDER BY TOTAL_CLAIM_AMOUNT DESC
"""
psql.sqldf(query,locals())

#TOTAL Claim Filed by Each VENDOR
query = """
SELECT
VENDOR_ID,
VENDOR_STATE,
SUM(CLAIM_AMOUNT) AS TOTAL_CLAIM_AMOUNT,
ROUND(AVG(CLAIM_AMOUNT),2) AS AVERAGE_CLAIM,
(SUM(CLAIM_AMOUNT) / CAST((SELECT SUM(CLAIM_AMOUNT) FROM combineTable) AS FLOAT) * 100) AS PERCENTAGE_TOTAL_CLAIM,
(SUM(CASE WHEN CLAIM_STATUS = 'D' THEN 1 ELSE 0 END) / CAST((SELECT COUNT(*) FROM combineTable WHERE CLAIM_STATUS = 'D') AS FLOAT) * 100) AS LIKELIHOOD_FRAUD_CLAIM
FROM combineTable
GROUP BY VENDOR_ID
ORDER BY TOTAL_CLAIM_AMOUNT DESC
"""
psql.sqldf(query,locals())

#Total Claim filed by STATE
query = """
SELECT
STATE,
SUM(CLAIM_AMOUNT) AS TOTAL_CLAIM_AMOUNT,
ROUND(AVG(CLAIM_AMOUNT),2) AS AVERAGE_CLAIM,
(SUM(CLAIM_AMOUNT) / CAST((SELECT SUM(CLAIM_AMOUNT) FROM combineTable) AS FLOAT) * 100) AS PERCENTAGE_TOTAL_CLAIM,
(SUM(CASE WHEN CLAIM_STATUS = 'D' THEN 1 ELSE 0 END) / CAST((SELECT COUNT(*) FROM combineTable WHERE CLAIM_STATUS = 'D') AS FLOAT) * 100) AS LIKELIHOOD_FRAUD_CLAIM

FROM combineTable
GROUP BY STATE
ORDER BY TOTAL_CLAIM_AMOUNT DESC
"""
sate_wise= psql.sqldf(query,locals())
sate_wise

query="""
SELECT
VENDOR_STATE,
AGENT_STATE,
INCIDENT_STATE,
INCIDENT_CITY,
INCIDENT_HOUR_OF_THE_DAY,
CLAIM_AMOUNT

FROM combineTable

GROUP BY
VENDOR_STATE, AGENT_STATE,INCIDENT_STATE, INCIDENT_CITY, INCIDENT_HOUR_OF_THE_DAY

ORDER BY
VENDOR_STATE,
AGENT_STATE,
INCIDENT_STATE,
INCIDENT_CITY,
INCIDENT_HOUR_OF_THE_DAY
"""
psql.sqldf(query,locals())

#all Insurance TYPES
query = """
SELECT
INSURANCE_TYPE,
SUM(CLAIM_AMOUNT) AS TOTAL_CLAIM_AMOUNT,
ROUND(AVG(CLAIM_AMOUNT),2) AS AVERAGE_CLAIM,
(SUM(CLAIM_AMOUNT) / CAST((SELECT SUM(CLAIM_AMOUNT) FROM combineTable) AS FLOAT) * 100) AS PERCENTAGE_TOTAL_CLAIM,
(SUM(CASE WHEN CLAIM_STATUS = 'D' THEN 1 ELSE 0 END) / CAST((SELECT COUNT(*) FROM combineTable WHERE CLAIM_STATUS = 'D') AS FLOAT) * 100) AS LIKELIHOOD_FRAUD_CLAIM

FROM combineTable
GROUP BY INSURANCE_TYPE
ORDER BY TOTAL_CLAIM_AMOUNT DESC
"""
insurance_type = psql.sqldf(query,locals())
insurance_type

#INCIDENT_SEVERITY
query = """
SELECT
COUNT(*) as count,
(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM combineTable)) as INCIDENT_SEV_PERC,
INCIDENT_SEVERITY,
SUM(CLAIM_AMOUNT) AS TOTAL_CLAIM_AMOUNT,
ROUND(AVG(CLAIM_AMOUNT),2) AS AVERAGE_CLAIM,
(SUM(CLAIM_AMOUNT) / CAST((SELECT SUM(CLAIM_AMOUNT) FROM combineTable) AS FLOAT) * 100) AS PERCENTAGE_TOTAL_CLAIM,
(SUM(CASE WHEN CLAIM_STATUS = 'D' THEN 1 ELSE 0 END) / CAST((SELECT COUNT(*) FROM combineTable WHERE CLAIM_STATUS = 'D') AS FLOAT) * 100) AS LIKELIHOOD_FRAUD_CLAIM

FROM combineTable
GROUP BY INCIDENT_SEVERITY
ORDER BY TOTAL_CLAIM_AMOUNT DESC
"""
incident_severity = psql.sqldf(query,locals())
incident_severity

#Lets see MOTOR by grouping with state and housetype
query = """
SELECT CLAIM_AMOUNT, MARITAL_STATUS, AGE, NO_OF_FAMILY_MEMBERS, STATE, EMPLOYMENT_STATUS, HOUSE_TYPE, SOCIAL_CLASS, INCIDENT_SEVERITY,POLICE_REPORT_AVAILABLE, CLAIM_STATUS
FROM combineTable
WHERE INSURANCE_TYPE = 'Motor'
GROUP BY STATE, HOUSE_TYPE
"""
psql.sqldf(query,locals())

#Check to find any annamolies between agent and vendor for filing false claim
#see in how many clims there where same agent and vendor involved

query = """SELECT AGENT_ID, VENDOR_ID, CLAIM_STATUS, COUNT(*) AS frequency
FROM combineTable
GROUP BY AGENT_ID, VENDOR_ID
HAVING COUNT(*) > 1
"""
psql.sqldf(query,locals())

"""# visualizing"""

fig1 = go.Figure(data=[go.Pie(
    labels=insurance_type['INSURANCE_TYPE'],
    values=insurance_type['TOTAL_CLAIM_AMOUNT'],
    hole=0.5,
    title='Insurance Type Wise Claim',
    marker_colors=py.colors.sequential.RdBu
)])
fig1.update_traces(text=insurance_type['INSURANCE_TYPE'], textposition='outside')


fig2 = go.Figure(data=[go.Pie(
    labels=insurance_type['INSURANCE_TYPE'],
    values=insurance_type['LIKELIHOOD_FRAUD_CLAIM'],
    hole=0.5,
    title='Insurance Type Wise Fraud Likelihood',
    marker_colors=py.colors.sequential.RdBu
)])
fig2.update_traces(text=insurance_type['INSURANCE_TYPE'], textposition='outside')


figs = make_subplots(rows=1, cols=2, specs=[[{'type': 'domain'}, {'type': 'domain'}]],
                    subplot_titles=("Total Claim Amount", "Likelihood of Fraud Claim"))


figs.add_trace(fig1.data[0], row=1, col=1)
figs.add_trace(fig2.data[0], row=1, col=2)


figs.update_layout(title_text="Insurance Type Wise Analysis")
figs.show()


figss = py.choropleth(sate_wise,
                    locations='STATE',
                    locationmode= "USA-states",
                    color='TOTAL_CLAIM_AMOUNT',
                    scope ='usa',
                    hover_data=['TOTAL_CLAIM_AMOUNT','PERCENTAGE_TOTAL_CLAIM', 'LIKELIHOOD_FRAUD_CLAIM'],
                    title='Claim by States',
                    color_continuous_scale='Viridis')
figss.update_layout(mapbox_style='open-street-map')
figss.show()

fig1s = py.bar(incident_severity, x="INCIDENT_SEVERITY", y="INCIDENT_SEV_PERC", template="seaborn", title='Incident Severity Percentage')
fig2s = py.bar(incident_severity, x="INCIDENT_SEVERITY", y="TOTAL_CLAIM_AMOUNT", template="seaborn", title='Total Claim Amount')

fig12s = make_subplots(rows=1, cols=2, subplot_titles=('Incident Severity Percentage', 'Total Claim Amount'))

fig12s.add_trace(fig1s.data[0], row=1, col=1)
fig12s.add_trace(fig2s.data[0], row=1, col=2)
fig12s.update_layout(template="seaborn", title_text="Incident_Severity")

fig12s.show()

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
ax1.hist(combineTable['CLAIM_AMOUNT'], bins=30, color='skyblue')
ax1.set_title('Claim Amount Distribution')
ax1.set_xlabel('Claim Amount')
ax1.set_ylabel('Frequency')
ax2.hist(combineTable['PREMIUM_AMOUNT'], bins=30, color='salmon')
ax2.set_title('Premium Amount Distribution')
ax2.set_xlabel('Premium Amount')
ax2.set_ylabel('Frequency')
plt.tight_layout()
plt.show()